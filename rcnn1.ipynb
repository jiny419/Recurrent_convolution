{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import merge, Convolution2D, MaxPooling2D, Input, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "\n",
    "def makeModel(nbChannels, shape1, shape2, nbClasses, nbRCL=5, nbFilters=128, filtersize = 3):\n",
    "\n",
    "\n",
    "\tmodel = BuildRCNN(nbChannels, shape1, shape2, nbClasses, nbRCL, nbFilters, filtersize)\n",
    "\treturn model\n",
    "\n",
    "def BuildRCNN(nbChannels, shape1, shape2, nbClasses, nbRCL, nbFilters, filtersize):\n",
    "    \n",
    "    def RCL_block(l_settings, l, pool=True, increase_dim=False):\n",
    "        input_num_filters = l_settings.output_shape[1]\n",
    "        if increase_dim:\n",
    "            out_num_filters = input_num_filters*2\n",
    "        else:\n",
    "            out_num_filters = input_num_filters\n",
    "\t\t   \n",
    "        conv1 = Convolution2D(out_num_filters, 1, 1, border_mode='same')\n",
    "        stack1 = conv1(l)   \t\n",
    "        stack2 = BatchNormalization()(stack1)\n",
    "        stack3 = PReLU()(stack2)\n",
    "        \n",
    "        conv2 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', init = 'he_normal')\n",
    "        stack4 = conv2(stack3)\n",
    "        stack5 = add([stack1, stack4])\n",
    "        stack6 = BatchNormalization()(stack5)\n",
    "        stack7 = PReLU()(stack6)\n",
    "    \t\n",
    "        conv3 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', weights = conv2.get_weights())\n",
    "        stack8 = conv3(stack7)\n",
    "        stack9 = add([stack1, stack8])\n",
    "        stack10 = BatchNormalization()(stack9)\n",
    "        stack11 = PReLU()(stack10)    \n",
    "        \n",
    "        conv4 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', weights = conv2.get_weights())\n",
    "        stack12 = conv4(stack11)\n",
    "        stack13 = add([stack1, stack12])\n",
    "        stack14 = BatchNormalization()(stack13)\n",
    "        stack15 = PReLU()(stack14)    \n",
    "        \n",
    "        if pool:\n",
    "            stack16 = MaxPooling2D((2, 2), border_mode='same')(stack15) \n",
    "            stack17 = Dropout(0.1)(stack16)\n",
    "        else:\n",
    "            stack17 = Dropout(0.1)(stack15)\n",
    "            \n",
    "        return stack17\n",
    "\n",
    "    #Build Network\n",
    "    input_img = Input(shape=(nbChannels, shape1, shape2))\n",
    "    conv_l = Convolution2D(nbFilters, filtersize, filtersize, border_mode='same', activation='relu')\n",
    "    l = conv_l(input_img)\n",
    "    \n",
    "    for n in range(nbRCL):\n",
    "        if n % 2 ==0:\n",
    "            l = RCL_block(conv_l, l, pool=False)\n",
    "        else:\n",
    "            l = RCL_block(conv_l, l, pool=True)\n",
    "    \n",
    "    out = Flatten()(l)        \n",
    "    l_out = Dense(nbClasses, activation = 'softmax')(out)\n",
    "    \n",
    "    model = Model(input = input_img, output = l_out)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c3d55fec490c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/user4/.conda/envs/tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/user4/.conda/envs/tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user4/.conda/envs/tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user4/.conda/envs/tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/user4/.conda/envs/tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 55000\n",
      "test : 10000\n"
     ]
    }
   ],
   "source": [
    "print('train :', len(mnist.train.images))\n",
    "print('test :', len(mnist.test.images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = mnist.train.images\n",
    "test_X = mnist.test.images\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_re = train_X.reshape(55000, 1, 28, 28)\n",
    "test_X_re = test_X.reshape(10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_re.shape, test_X_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.makeModel(nbChannels, shape1, shape2, nbClasses, nbRCL=5, nbFilters=128, filtersize=3)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), padding=\"same\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 3), weights=[array([[[..., padding=\"same\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 3), weights=[array([[[..., padding=\"same\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\")`\n",
      "/home/user4/.conda/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "model = makeModel(1, train_X_re.shape[1], train_X_re.shape[2], train_y.shape[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 21s 388us/step - loss: 0.7175\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 21s 379us/step - loss: 0.7015\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 21s 386us/step - loss: 0.6769\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 0.6609\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 21s 375us/step - loss: 0.6391\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 21s 384us/step - loss: 0.6346\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 0.6156\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 21s 385us/step - loss: 0.6121\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 21s 385us/step - loss: 0.5982\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 21s 385us/step - loss: 0.5838\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 21s 382us/step - loss: 0.5754\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 0.5659\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 21s 384us/step - loss: 0.5603\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 21s 380us/step - loss: 0.5513\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 22s 392us/step - loss: 0.5427\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 21s 384us/step - loss: 0.5382\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 0.5319\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 21s 380us/step - loss: 0.5297\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 21s 381us/step - loss: 0.5295\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 21s 383us/step - loss: 0.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab647d1be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X_re, train_y, epochs = 20, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9303"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = np.argmax(model.predict(test_X_re), axis=1)\n",
    "\n",
    "np.mean(pred == np.argmax(test_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor]",
   "language": "python",
   "name": "conda-env-tensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
